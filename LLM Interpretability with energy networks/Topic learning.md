### 1. BERTopic: Neural topic modeling with a class-based TF-IDF procedure

- **Authors**: Maarten Grootendorst
- **Year**: 2022
- **Link**: [https://arxiv.org/abs/2203.00727](https://arxiv.org/abs/2203.00727)

**What it does**:  
BERTopic uses **sentence embeddings** (commonly from transformer models) and a class-based TF-IDF procedure to generate coherent topics. It’s known for its ease of use and often produces high-quality, interpretable topics.

---

### 3. Top2Vec: Distributed Representations of Topics

- **Author**: Dimo Angelov
- **Year**: 2020 (with continued updates and widespread adoption in subsequent years)
- **Link**: [https://arxiv.org/abs/2008.09470](https://arxiv.org/abs/2008.09470)

**What it does**:  
Top2Vec automatically discovers **topic vectors** by jointly embedding documents and words in the same vector space, then finding dense regions of semantically similar documents (i.e., topics). It remains a popular choice for **unsupervised topic detection**.

---

### 4. ZeroShotTM: A Practical Approach for Zero-Shot Topic Modeling

- **Authors**: Derek Tam, Richard Yuanzhe Pang, et al.
- **Year**: 2021
- **Link**: [https://arxiv.org/abs/2109.04422](https://arxiv.org/abs/2109.04422)

**What it does**:  
Proposes **ZeroShotTM**, which leverages large pre-trained language models to **assign topic labels** without requiring labeled training data for those topics—especially useful when you have domain-specific or emergent topics that lack large training corpora.

---

## Tips for Keeping Up to Date

- **arXiv**: If you want the _very latest_ preprints, search [arXiv.org](https://arxiv.org/) for keywords like _“topic modeling,”_ _“topic extraction,”_ or _“neural topic modeling.”_
- **Google Scholar**: Filter search results by year (e.g., 2022, 2023) to see recent, peer-reviewed articles.
- **Conference Proceedings**: Look at top-tier NLP/ML conferences (e.g., ACL, EMNLP, NeurIPS, ICML) and filter by “topic modeling” or “topic extraction” in the proceedings’ search bar.

Each paper above is considered **valid** and is frequently cited in research about **topic extraction**. They describe newer techniques that go beyond classic LDA (Latent Dirichlet Allocation), using deep neural networks, pre-trained language models, or contextual embeddings.


