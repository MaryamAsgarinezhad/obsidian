network course
- how a new machine is added to the network? 
- vmware or virtual box in network
- cocjer, virtual machine, virtual box,...
- status codes meaning? 
- proxy?
- vpn?
- vps?
- making a vpn- system proxy - tunel - reverse proxy
- URL , URI

os course

kuber

Bot warden

https://www.linkedin.com/posts/mmafshari_navigating-the-sd-card-dilemma-in-hpe-servers-activity-7198638531043291139-A47F?utm_source=share&utm_medium=member_android




local M = {}  
  
function M.log_request()  
    local log_file = ngx.var.arg_zb_svc  
    local log_teams_list = ngx.var.arg_log_teams_list and ngx.var.arg_log_teams_list:split(",") or {}  
  
    local function is_in_list(value, list)  
        for _, v in ipairs(list) do  
            if v == value then  
                return true  
            end  
        end        return false  
    end  
  
    if log_file and log_file ~= "" and is_in_list(log_file, log_teams_list) then



local function is_in_list(value, list)  
     for _, v in list do  
         if v == value then  
             return true  
         end  
     end  
     return false  
end












if is_in_list(log_file, cdn_log_team_list) then  
          local log_module = require("openresty_team_specific_log_access")  
          log_module.log_request()  
          ngx.log(ngx.ERR, "Done ")  
 end  
  
 local env = "{{ env }}"  
 local node_type = "{% if inventory_hostname in cdn_loadbalancers %}loadbalancer{% else %}cache{% endif %}"  
 local service_name = node_type .. "-sre-cdn"  
 local host = ngx.var.host  
  
{% if inventory_hostname in cdn_loadbalancers %}  
  
         local bytes_sent = ngx.var.bytes_sent  
         metric_requests_proxy:inc(1, {env, ngx.var.status,service_name})  
         metric_latency_proxy:observe(tonumber(ngx.var.request_time), {env,service_name})  
  
  if ngx.status == 200 then  
         metric_request_body_sent_size_proxy:observe(tonumber(bytes_sent), {env,ngx.var.app_name,service_name})  
         metric_requests_per_host_number:inc(1, {env,host,service_name})  
         metric_requests_per_server_number:inc(1, {env,'{{ ansible_default_ipv4.address }}',service_name})  
  
  end  
{% else %}  
        metric_requests_total:inc(1, {env,ngx.var.status,service_name})  
        metric_requests_teams:inc(1, {env,ngx.var.status,service_name, ngx.var.app_name})  
        metric_latency:observe(tonumber(ngx.var.request_time), {env,service_name})  
        metric_upstream_latency:observe(((tonumber(ngx.var.upstream_connect_time) or 0) + (tonumber(ngx.var.upstream_header_time) or 0) + (tonumber(ngx.var.upstream_response_time) or 0)), {env,service_name})  
  
  if ngx.status == 200 then  
  
       metric_requests_per_type_number:inc(1, {env,ngx.var.type, ngx.var.app_name,service_name})  
       metric_requests_per_server_number:inc(1, {env,'{{ ansible_default_ipv4.address }}',service_name})  
  
       if ngx.var.upstream_cache_status == "HIT" then  
          metric_requests_hit_number:inc(1, {env,ngx.var.app_name,service_name})  
       else  
          metric_latency_envoy_proxy:observe(tonumber(ngx.now()) - tonumber(ngx.var.proxy_start_time), {env,service_name,ngx.var.proxy_selected})  
          metric_requests_miss_number:inc(1, {env,ngx.var.app_name,service_name})  
       end  
  
  end  
  
  
{% endif %}